
VAE(
  (loss_func): MSELoss()
  (encoder): Sequential(
    (0): Linear(in_features=10, out_features=100, bias=True)
    (1): Sigmoid()
  )
  (u): Sequential(
    (0): Linear(in_features=100, out_features=50, bias=True)
    (1): Affine()
  )
  (logv2): Sequential(
    (0): Linear(in_features=100, out_features=50, bias=True)
    (1): Affine()
  )
  (decoder): Sequential(
    (0): Linear(in_features=50, out_features=100, bias=True)
    (1): Sigmoid()
    (2): Linear(in_features=100, out_features=10, bias=True)
    (3): Affine()
  )
)

run paras: {'run_times': 1, 'multirun_seed': 'r*2', '_run_id': '', 'e': 18, 'load_para_type': None, 'load_sub': None, 'load_file_name': None, 'view_addi_info': ['recon_loss', 'kl_loss', 'loss'], 'if_log': True, 'if_epoch_eval': None, 'if_vmap': False, 'if_save_excel': True, 'if_save_plot': True, 'fd_pr': ['re-T2-ineq'], 'fd_pr_dt': [{'mm': 're', 'ts': 'T2', 'thrd_meth': 'ineq'}], 'fd_pr_name': ['re-T2-ineq'], 'if_minus_mean': True, 'if_use_lstsq': False, 'expt_FAR': 0.005, 'if_plot_mm_kde': False, 'if_plot_score_hm': False, 'if_mm_tab': False, 'if_mm_tsne': False, 'alld_error': 0.005, 'cl': 0.995, 'if_intp': False}

Train VAE[unsup_res]_CSTR_fd_Act2 in cuda:
torch.Size([16, 10])
Traceback (most recent call last):
  File "F:\torch_joff\joff\_run\_run_model.py", line 67, in _run_with_log
    _run_n(self, p)
  File "F:\torch_joff\joff\_run\_run_model.py", line 111, in _run_n
    train_model(self, **p)
  File "F:\torch_joff\joff\_run\_run_model.py", line 199, in train_model
    else: batch_training(self)
  File "F:\torch_joff\joff\_run\_epoch.py", line 30, in batch_training
    self.loss.backward()
  File "F:\Anaconda\lib\site-packages\torch\_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "F:\Anaconda\lib\site-packages\torch\autograd\__init__.py", line 193, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "F:\Anaconda\lib\site-packages\torch\autograd\__init__.py", line 88, in _make_grads
    raise RuntimeError("grad can be implicitly created only for scalar outputs")
RuntimeError: grad can be implicitly created only for scalar outputs
