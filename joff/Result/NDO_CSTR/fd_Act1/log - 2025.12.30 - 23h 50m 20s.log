
NDO(
  (loss_func): MSELoss()
  (seq): Sequential(
    (layer_0): Layer(
      (0): RNNCell(in_features=53, out_features=200, bias=True)
      (1): Gaussian()
    )
    (layer_1): Layer(
      (0): Dropout(p=0.0167, inplace=False)
      (1): RNNCell(in_features=250, out_features=150, bias=True)
      (2): Tanh()
    )
    (layer_2): Layer(
      (0): Dropout(p=0.0133, inplace=False)
      (1): RNNCell(in_features=200, out_features=50, bias=True)
      (2): Affine()
    )
  )
)

run paras: {'run_times': 1, 'multirun_seed': 'r*2', '_run_id': '', 'e': 3, 'load_para_type': None, 'load_sub': None, 'load_file_name': None, 'load_path_replace': None, 'view_addi_info': ['observer_loss', 'L_abs_norm', 'stability_loss', 'loss'], 'if_log': True, 'if_epoch_eval': None, 'if_vmap': False, 'if_save_excel': True, 'if_save_plot': True, 'fd_pr': ['cust_mm_ey-T2&Q-kde'], 'fd_pr_dt': [{'mm': 'cust_mm_ey', 'ts': 'T2', 'thrd_meth': 'kde'}, {'mm': 'cust_mm_ey', 'ts': 'Q', 'thrd_meth': 'kde'}], 'fd_pr_name': ['cust_mm_ey-T2-kde', 'cust_mm_ey-Q-kde'], 'expt_FAR': 0.005, 'ts_post_op': None, 'if_use_lstsq': True, 'if_plot_mm_kde': False, 'if_plot_score_hm': False, 'if_plot_cov_inv': False, 'if_save_ts': False, 'alld_error': 0.005, 'cl': 0.995, 'if_intp': False}

Train NDO_CSTR/fd_Act1 via cuda:
0, 0, -0.0046242703683674335
0, 1, -0.004468230996280909
0, 2, -0.0044588372111320496
0, 3, -0.004540182184427977
0, 4, -0.0044858078472316265
1, 0, -0.004429707303643227
1, 1, -0.004492632113397121
1, 2, -0.004239871632307768
1, 3, -0.004430844914168119
1, 4, -0.0043907552026212215
2, 0, -0.004611492156982422
2, 1, -0.0044865682721138
2, 2, -0.004514605738222599
2, 3, -0.00452088937163353
2, 4, -0.004505528137087822
3, 0, -0.00433945469558239
3, 1, -0.004340602084994316
3, 2, -0.004339192062616348
3, 3, -0.004356411751359701
3, 4, -0.004339279606938362
4, 0, -0.004281128756701946
4, 1, -0.004283460788428783
4, 2, -0.004283696413040161
4, 3, -0.004283640068024397
4, 4, -0.004283696413040161
5, 0, -0.004197970498353243
5, 1, -0.004197970498353243
5, 2, -0.004197970498353243
5, 3, -0.004197970498353243
5, 4, -0.004197970498353243
6, 0, -0.004132833797484636
6, 1, -0.004132833797484636
6, 2, -0.004132833797484636
6, 3, -0.004132833797484636
6, 4, -0.004132833797484636
7, 0, -0.004072067327797413
7, 1, -0.004072067327797413
7, 2, -0.004072067327797413
7, 3, -0.004072067327797413
7, 4, -0.004072067327797413
8, 0, -0.004201212432235479
8, 1, -0.004201212432235479
8, 2, -0.004201212432235479
8, 3, -0.004201212432235479
8, 4, -0.004201212432235479
9, 0, -0.0043052141554653645
9, 1, -0.0043052141554653645
9, 2, -0.0043052141554653645
9, 3, -0.0043052141554653645
9, 4, -0.0043052141554653645
Epoch: 1 - 10/2398 | observer_loss = 114452985734917498339328.0000, L_abs_norm = 0.0516, stability_loss = 285.4348, loss = 114452985734917498339328.0000                10, 0, -0.004297750070691109
10, 1, -0.004297750070691109
10, 2, -0.004297750070691109
10, 3, -0.004297750070691109
10, 4, -0.004297750070691109
11, 0, -0.004297750070691109
11, 1, -0.004297750070691109
11, 2, -0.004297750070691109
11, 3, -0.004297750070691109
11, 4, -0.004297750070691109
12, 0, -0.004297750070691109
12, 1, -0.004297750070691109
12, 2, -0.004297750070691109
12, 3, -0.004297750070691109
12, 4, -0.004297750070691109
13, 0, -0.004297750070691109
13, 1, -0.004297750070691109
13, 2, -0.004297750070691109
13, 3, -0.004297750070691109
13, 4, -0.004297750070691109
14, 0, -0.004297750070691109
14, 1, -0.004297750070691109
14, 2, -0.004297750070691109
14, 3, -0.004297750070691109
14, 4, -0.004297750070691109
15, 0, -0.004297750070691109
15, 1, -0.004297750070691109
15, 2, -0.004297750070691109
15, 3, -0.004297750070691109
15, 4, -0.004297750070691109
16, 0, -0.004297750070691109
16, 1, -0.004297750070691109
16, 2, -0.004297750070691109
16, 3, -0.004297750070691109
16, 4, -0.004297750070691109
17, 0, -0.004297750070691109
17, 1, -0.004297750070691109
17, 2, -0.004297750070691109
17, 3, -0.004297750070691109
17, 4, -0.004297750070691109
Traceback (most recent call last):
  File "F:\torch_joff\joff\_run\_run_model.py", line 67, in _run_with_log
    _run_n(self, p)
  File "F:\torch_joff\joff\_run\_run_model.py", line 111, in _run_n
    train_model(self, **p)
  File "F:\torch_joff\joff\_run\_run_model.py", line 199, in train_model
    else: batch_training(self)
          ^^^^^^^^^^^^^^^^^^^^
  File "F:\torch_joff\joff\_run\_epoch.py", line 31, in batch_training
    self.loss.backward()
  File "F:\anaconda3\Lib\site-packages\torch\_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "F:\anaconda3\Lib\site-packages\torch\autograd\__init__.py", line 354, in backward
    _engine_run_backward(
  File "F:\anaconda3\Lib\site-packages\torch\autograd\graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Function 'MmBackward0' returned nan values in its 0th output.
