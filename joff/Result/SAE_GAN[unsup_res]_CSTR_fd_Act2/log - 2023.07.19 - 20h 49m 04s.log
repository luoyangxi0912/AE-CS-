
SAE_GAN(
  (loss_func): MSELoss()
  (generator): Sequential(
    (0): Sequential(
      (0): Linear(in_features=10, out_features=100, bias=True)
      (1): Sigmoid()
      (2): Linear(in_features=100, out_features=50, bias=True)
      (3): Sigmoid()
    )
    (1): Sequential(
      (0): Linear(in_features=50, out_features=100, bias=True)
      (1): Sigmoid()
      (2): Linear(in_features=100, out_features=10, bias=True)
      (3): Affine()
    )
  )
  (discriminator): Sequential(
    (0): Linear(in_features=10, out_features=100, bias=True)
    (1): Sigmoid()
    (2): Linear(in_features=100, out_features=1, bias=True)
    (3): Sigmoid()
  )
)

run paras: {'run_times': 1, 'multirun_seed': 'r*2', '_run_id': '', 'e': 24, 'load_para_type': None, 'load_sub': None, 'load_file_name': None, 'view_addi_info': ['recon_loss', 'g_loss', 'd_real_loss', 'd_fake_loss'], 'if_log': True, 'if_epoch_eval': None, 'if_vmap': False, 'if_save_excel': True, 'if_save_plot': True, 'fd_pr': ['re-T2-kde', 'lv-\\phi_{\\cal{D}}-kde'], 'fd_pr_dt': [{'mm': 're', 'ts': 'T2', 'thrd_meth': 'kde'}, {'mm': 'lv', 'ts': '\\phi_{\\cal{D}}', 'thrd_meth': 'kde'}], 'fd_pr_name': ['re-T2-kde', 'lv-\\phi_{\\cal{D}}-kde'], 'if_use_lstsq': False, 'if_ts_post': None, 'expt_FAR': 0.005, 'if_plot_mm_kde': [False, True], 'if_plot_score_hm': False, 'if_mm_tab': False, 'if_mm_tsne': False, 'alld_error': 0.005, 'cl': 0.995, 'if_intp': False}

Train SAE_GAN[unsup_res]_CSTR_fd_Act2 in cuda:
Traceback (most recent call last):
  File "F:\torch_joff\joff\_run\_run_model.py", line 67, in _run_with_log
    _run_n(self, p)
  File "F:\torch_joff\joff\_run\_run_model.py", line 111, in _run_n
    train_model(self, **p)
  File "F:\torch_joff\joff\_run\_run_model.py", line 198, in train_model
    if hasattr(self, '_batch_training'): self._batch_training()  # custom training
  File "F:\torch_joff\joff\_model\_variant\sae_gan.py", line 87, in _batch_training
    batch_training(self, loader)
  File "F:\torch_joff\joff\_run\_epoch.py", line 26, in batch_training
    self._forward(input)    # custom train
  File "F:\torch_joff\joff\_model\_variant\sae_gan.py", line 97, in _forward
    md_loss = 1/ np.sum((self.discriminator(x_n) - self.discriminator(x_f))**2)
  File "<__array_function__ internals>", line 180, in sum
  File "F:\Anaconda\lib\site-packages\numpy\core\fromnumeric.py", line 2298, in sum
    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,
  File "F:\Anaconda\lib\site-packages\numpy\core\fromnumeric.py", line 84, in _wrapreduction
    return reduction(axis=axis, out=out, **passkwargs)
TypeError: sum() received an invalid combination of arguments - got (axis=NoneType, out=NoneType, ), but expected one of:
 * (*, torch.dtype dtype)
      didn't match because some of the keywords were incorrect: axis, out
 * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)
 * (tuple of names dim, bool keepdim, *, torch.dtype dtype)

