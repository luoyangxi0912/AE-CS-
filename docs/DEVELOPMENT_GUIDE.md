# AE-CS ç¼ºå¤±æ•°æ®å¡«è¡¥é¡¹ç›® - å®Œæ•´å¼€å‘æŒ‡å—

> ä»Žé›¶åˆ°å¯è¿è¡Œæ¨¡åž‹çš„å®Œæ•´å¼€å‘æµç¨‹è®°å½•

---

## ðŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
2. [çŽ¯å¢ƒé…ç½®](#2-çŽ¯å¢ƒé…ç½®)
3. [é¡¹ç›®ç»“æž„](#3-é¡¹ç›®ç»“æž„)
4. [æ•°æ®å‡†å¤‡](#4-æ•°æ®å‡†å¤‡)
5. [æ¨¡åž‹å¼€å‘](#5-æ¨¡åž‹å¼€å‘)
6. [è®­ç»ƒæµç¨‹](#6-è®­ç»ƒæµç¨‹)
7. [è¯„ä¼°æ–¹æ³•](#7-è¯„ä¼°æ–¹æ³•)
8. [å…³é”®Bugä¿®å¤](#8-å…³é”®bugä¿®å¤)
9. [æ€§èƒ½ä¼˜åŒ–åŽ†ç¨‹](#9-æ€§èƒ½ä¼˜åŒ–åŽ†ç¨‹)
10. [å¿«é€Ÿå¼€å§‹](#10-å¿«é€Ÿå¼€å§‹)
11. [å¸¸è§é—®é¢˜](#11-å¸¸è§é—®é¢˜)

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 ä»»åŠ¡æè¿°
- **ä»»åŠ¡**: å·¥ä¸šæ—¶é—´åºåˆ—æ•°æ®çš„ç¼ºå¤±å€¼å¡«è¡¥
- **æ•°æ®é›†**: hangmei_90_æ‹¼æŽ¥å¥½çš„.csv
  - æ ·æœ¬æ•°: 2793
  - ç‰¹å¾æ•°: 44
  - ç¼ºå¤±çŽ‡: 20% (äººå·¥ç”Ÿæˆ)
  - ç¼ºå¤±ç±»åž‹: MCAR (å®Œå…¨éšæœºç¼ºå¤±)

### 1.2 æ¨¡åž‹é€‰æ‹©
- **æ¨¡åž‹åç§°**: AE-CS (AutoEncoder with Coherent denoising and Spatio-temporal neighborhood-preserving embedding)
- **æ ¸å¿ƒæ€æƒ³**:
  - ä½¿ç”¨GRUè‡ªç¼–ç å™¨å­¦ä¹ æ—¶é—´åºåˆ—çš„æ½œåœ¨è¡¨ç¤º
  - é€šè¿‡BernoulliæŸåå¢žå¼ºé²æ£’æ€§
  - ä¿æŒç©ºé—´å’Œæ—¶é—´é‚»åŸŸç»“æž„

### 1.3 æ€§èƒ½ç›®æ ‡
- **ç›®æ ‡æŒ‡æ ‡**: RÂ² > 0.5, MAE < 0.5
- **æœ€ç»ˆæ€§èƒ½**: RÂ² = 0.691, MAE = 0.445, RMSE = 0.585 âœ…

---

## 2. çŽ¯å¢ƒé…ç½®

### 2.1 åˆ›å»ºPythonè™šæ‹ŸçŽ¯å¢ƒ

```bash
# Windows
python -m venv venv_tf210_gpu

# æ¿€æ´»çŽ¯å¢ƒ
venv_tf210_gpu\Scripts\activate
```

**ä¸ºä»€ä¹ˆä½¿ç”¨è™šæ‹ŸçŽ¯å¢ƒï¼Ÿ**
- éš”ç¦»é¡¹ç›®ä¾èµ–ï¼Œé¿å…ç‰ˆæœ¬å†²çª
- ç¡®ä¿å¯å¤çŽ°æ€§

### 2.2 å®‰è£…ä¾èµ–

```bash
# æ ¸å¿ƒæ¡†æž¶
pip install tensorflow==2.10.0

# æ•°æ®å¤„ç†
pip install numpy pandas scikit-learn

# å¯è§†åŒ–
pip install matplotlib seaborn

# è¿›åº¦æ¡
pip install tqdm

# åŠ é€Ÿk-NNæœç´¢ (å¯é€‰)
pip install faiss-cpu  # CPUç‰ˆæœ¬
# æˆ–
pip install faiss-gpu  # GPUç‰ˆæœ¬ (éœ€è¦CUDA)
```

**å…³é”®ä¾èµ–è¯´æ˜Ž**:
- **TensorFlow 2.10.0**: ä¸ŽPython 3.9å…¼å®¹ï¼Œæ”¯æŒGRU/LSTM
- **FAISS**: å¿«é€Ÿè¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ï¼ŒåŠ é€Ÿç©ºé—´/æ—¶é—´é‚»åŸŸè®¡ç®—

### 2.3 éªŒè¯GPUé…ç½®

```python
import tensorflow as tf
print("GPUå¯ç”¨:", tf.config.list_physical_devices('GPU'))
```

**é¢„æœŸè¾“å‡º**:
```
GPUå¯ç”¨: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
```

---

## 3. é¡¹ç›®ç»“æž„

### 3.1 ç›®å½•ç»“æž„

```
D:\æ•°æ®è¡¥å…¨/
â”‚
â”œâ”€â”€ data/                           # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessor.py            # æ•°æ®é¢„å¤„ç† â­ å·²ä¿®å¤æ•°æ®æ³„éœ²
â”‚   â””â”€â”€ dataset.py                 # TensorFlowæ•°æ®é›†å°è£…
â”‚
â”œâ”€â”€ models/                         # æ¨¡åž‹æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ encoder.py                 # GRUç¼–ç å™¨
â”‚   â”œâ”€â”€ decoder.py                 # GRUè§£ç å™¨
â”‚   â”œâ”€â”€ gating.py                  # é—¨æŽ§èžåˆç½‘ç»œ
â”‚   â”œâ”€â”€ neighborhood.py            # é‚»åŸŸæœç´¢æ¨¡å—
â”‚   â”œâ”€â”€ losses.py                  # æŸå¤±å‡½æ•° â­ å·²ä¿®å¤æ•°é‡çº§
â”‚   â””â”€â”€ ae_cs.py                   # AE-CSä¸»æ¨¡åž‹
â”‚
â”œâ”€â”€ checkpoints/                    # æ¨¡åž‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ fixed_model/               # ä¿®å¤åŽçš„æœ€ä½³æ¨¡åž‹
â”‚   â”œâ”€â”€ reduced_reg/               # åŽ†å²æ¨¡åž‹
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ results/                        # è¯„ä¼°ç»“æžœ
â”‚   â”œâ”€â”€ fixed_model/
â”‚   â”‚   â”œâ”€â”€ metrics.json
â”‚   â”‚   â”œâ”€â”€ feature_performance.csv
â”‚   â”‚   â””â”€â”€ *.png
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â””â”€â”€ eda.py                     # æŽ¢ç´¢æ€§æ•°æ®åˆ†æž
â”‚
â”œâ”€â”€ train.py                        # è®­ç»ƒè„šæœ¬ â­
â”œâ”€â”€ evaluate.py                     # è¯„ä¼°è„šæœ¬ â­
â”œâ”€â”€ diagnose.py                     # è¯Šæ–­è„šæœ¬ â­
â”‚
â”œâ”€â”€ hangmei_90_æ‹¼æŽ¥å¥½çš„.csv         # åŽŸå§‹æ•°æ®
â””â”€â”€ DEVELOPMENT_GUIDE.md            # æœ¬æ–‡æ¡£
```

### 3.2 æ ¸å¿ƒæ–‡ä»¶è¯´æ˜Ž

| æ–‡ä»¶ | ä½œç”¨ | å…³é”®ç‚¹ |
|------|------|--------|
| `train.py` | æ¨¡åž‹è®­ç»ƒ | å®žçŽ°Algorithm 1ï¼Œæ”¯æŒearly stopping |
| `evaluate.py` | æ¨¡åž‹è¯„ä¼° | è®¡ç®—RÂ²/MAE/RMSEï¼Œç”Ÿæˆå¯è§†åŒ– |
| `diagnose.py` | é—®é¢˜è¯Šæ–­ | æ£€æŸ¥æ•°æ®æ³„éœ²ã€æŸå¤±æ•°é‡çº§ã€è¿‡æ‹Ÿåˆèƒ½åŠ› |
| `preprocessor.py` | æ•°æ®é¢„å¤„ç† | **å·²ä¿®å¤æ•°æ®æ³„éœ²é—®é¢˜** |
| `losses.py` | æŸå¤±è®¡ç®— | **å·²ä¿®å¤æ•°é‡çº§å¤±è¡¡é—®é¢˜** |

---

## 4. æ•°æ®å‡†å¤‡

### 4.1 æ•°æ®åŠ è½½

```python
from data.preprocessor import HangmeiPreprocessor

preprocessor = HangmeiPreprocessor(
    scaler_type='standard',  # æ ‡å‡†åŒ–
    window_size=48,          # æ—¶é—´çª—å£
    stride=1                 # æ»‘åŠ¨æ­¥é•¿
)
```

### 4.2 æ•°æ®é¢„å¤„ç†æµç¨‹

#### â­ æ­£ç¡®çš„é¢„å¤„ç†é¡ºåºï¼ˆå·²ä¿®å¤ï¼‰

```python
# 1. åŠ è½½åŽŸå§‹æ•°æ®
df = pd.read_csv('hangmei_90_æ‹¼æŽ¥å¥½çš„.csv')

# 2. å…ˆåˆ’åˆ†æ•°æ®é›†ï¼ˆæ—¶é—´åºåˆ—æŒ‰é¡ºåºåˆ’åˆ†ï¼‰
train_data = data[:train_end]
val_data = data[train_end:val_end]
test_data = data[val_end:]

# 3. å½’ä¸€åŒ–ï¼šåªåœ¨è®­ç»ƒé›†ä¸Šfit â­ å…³é”®æ­¥éª¤
train_normalized = scaler.fit_transform(train_data)      # fit
val_normalized = scaler.transform(val_data)              # transform only
test_normalized = scaler.transform(test_data)            # transform only

# 4. åˆ›å»ºç¼ºå¤±å€¼æŽ©ç 
train_mask = create_missing_mask(train_normalized, missing_rate=0.2)
val_mask = create_missing_mask(val_normalized, missing_rate=0.2)
test_mask = create_missing_mask(test_normalized, missing_rate=0.2)

# 5. åˆ›å»ºæ—¶é—´çª—å£
train_windows = create_windows(train_normalized, window_size=48)
val_windows = create_windows(val_normalized, window_size=48)
test_windows = create_windows(test_normalized, window_size=48)
```

#### âŒ é”™è¯¯çš„é¢„å¤„ç†é¡ºåºï¼ˆä¼šå¯¼è‡´æ•°æ®æ³„éœ²ï¼‰

```python
# é”™è¯¯ï¼šå…ˆå½’ä¸€åŒ–æ•´ä¸ªæ•°æ®é›†
normalized = scaler.fit_transform(data)  # âŒ æµ‹è¯•é›†ä¿¡æ¯æ³„éœ²ï¼

# ç„¶åŽæ‰åˆ’åˆ†
train, val, test = split(normalized)
```

### 4.3 éªŒè¯å½’ä¸€åŒ–æ˜¯å¦æ­£ç¡®

```python
print(f"Train mean: {train_normalized.mean():.6f}")  # åº”è¯¥ â‰ˆ 0
print(f"Train std:  {train_normalized.std():.6f}")   # åº”è¯¥ â‰ˆ 1
print(f"Val mean:   {val_normalized.mean():.6f}")    # å¯èƒ½ â‰  0
print(f"Test mean:  {test_normalized.mean():.6f}")   # å¯èƒ½ â‰  0
```

**é¢„æœŸè¾“å‡º**:
```
Train mean: -0.000000  âœ…
Train std:  1.000000   âœ…
Val mean:   -0.821307  âœ… (ä¸ç­‰äºŽ0æ˜¯æ­£å¸¸çš„)
Test mean:  0.524690   âœ… (ä¸ç­‰äºŽ0æ˜¯æ­£å¸¸çš„)
```

---

## 5. æ¨¡åž‹å¼€å‘

### 5.1 æ¨¡åž‹æž¶æž„

```
è¾“å…¥: X (batch, time=48, features=44), M (mask)
  â†“
[1] GRU Encoder (128 units)
  â†“
  z_orig (batch, latent=32)
  â†“
[2] ç©ºé—´/æ—¶é—´é‚»åŸŸæœç´¢ (FAISS k-NN, k=5)
  â†“
  z_space, z_time
  â†“
[3] é—¨æŽ§èžåˆç½‘ç»œ
  â†“
  z_fused = Î±Â·z_orig + (1-Î±)Â·[z_space + z_time]
  â†“
[4] GRU Decoder
  â†“
è¾“å‡º: X_hat (é‡å»ºæ•°æ®)
```

### 5.2 æŸå¤±å‡½æ•°

#### â­ ä¿®å¤åŽçš„æŸå¤±å‡½æ•°

```python
# æ€»æŸå¤±
L_total = L_recon + Î»1Â·L_consist + Î»2Â·L_space + Î»3Â·L_time

# 1. é‡å»ºæŸå¤± (æ ¸å¿ƒ)
L_recon = ||ï¼ˆX - X_hat) âŠ™ M||Â²_F / |M|

# 2. ä¸€è‡´æ€§æŸå¤± (BernoulliæŸå)
L_consist = Î£ w^(k) ||Z^(k) - Z_orig||Â²

# 3. ç©ºé—´é‚»åŸŸä¿æŒæŸå¤± â­ å·²ä¿®å¤
L_space = mean(weighted_distances)  # ä½¿ç”¨meanè€Œä¸æ˜¯sum

# 4. æ—¶é—´é‚»åŸŸä¿æŒæŸå¤± â­ å·²ä¿®å¤
L_time = mean(weighted_distances)   # ä½¿ç”¨meanè€Œä¸æ˜¯sum
```

**ä¿®å¤å‰åŽå¯¹æ¯”**:
```
ä¿®å¤å‰:
  L_recon = 0.64
  L_space = 213.33 âŒ (æ•°é‡çº§è¿‡å¤§ï¼)
  L_time = 258.73  âŒ (æ•°é‡çº§è¿‡å¤§ï¼)

ä¿®å¤åŽ:
  L_recon = 0.65
  L_space = 1.67   âœ… (æ•°é‡çº§åˆç†)
  L_time = 1.75    âœ… (æ•°é‡çº§åˆç†)
```

---

## 6. è®­ç»ƒæµç¨‹

### 6.1 åŸºæœ¬è®­ç»ƒå‘½ä»¤

```bash
"venv_tf210_gpu\Scripts\python.exe" train.py \
    --epochs 20 \
    --batch_size 16 \
    --latent_dim 32 \
    --learning_rate 0.001 \
    --lambda1 1.0 \
    --lambda2 0.01 \
    --lambda3 0.01 \
    --dropout_rate 0.1 \
    --l2_reg 0.0005 \
    --seed 42 \
    --checkpoint_dir ./checkpoints/my_model
```

### 6.2 è®­ç»ƒå‚æ•°è¯¦è§£

| å‚æ•° | æŽ¨èå€¼ | è¯´æ˜Ž | è°ƒä¼˜å»ºè®® |
|------|--------|------|----------|
| `--epochs` | 20 | è®­ç»ƒè½®æ•° | å¯å¢žåŠ åˆ°30-50 |
| `--batch_size` | 16 | æ‰¹æ¬¡å¤§å° | 32å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆ |
| `--latent_dim` | 32 | æ½œåœ¨ç»´åº¦ | 64ä¼šè®­ç»ƒå¤±è´¥ |
| `--learning_rate` | 0.001 | å­¦ä¹ çŽ‡ | å…³é”®å‚æ•° |
| `--lambda1` | 1.0 | ä¸€è‡´æ€§æƒé‡ | å›ºå®šä¸º1.0 |
| `--lambda2` | 0.01 | ç©ºé—´æƒé‡ | â­ 0.03-0.05ä¼šå¤±è´¥ |
| `--lambda3` | 0.01 | æ—¶é—´æƒé‡ | â­ 0.03-0.05ä¼šå¤±è´¥ |
| `--dropout_rate` | 0.1 | Dropoutæ¯”çŽ‡ | 0.2ä¼šè¿‡åº¦æ­£åˆ™åŒ– |
| `--l2_reg` | 0.0005 | L2æ­£åˆ™åŒ– | 0.001ä¼šè¿‡åº¦æ­£åˆ™åŒ– |
| `--k_spatial` | 5 | ç©ºé—´é‚»å±…æ•° | å›ºå®š |
| `--k_temporal` | 5 | æ—¶é—´é‚»å±…æ•° | å›ºå®š |

### 6.3 è®­ç»ƒè¿‡ç¨‹ç›‘æŽ§

è®­ç»ƒæ—¶ä¼šçœ‹åˆ°å¦‚ä¸‹è¾“å‡ºï¼š

```
Epoch 1/20
  Train Loss: 0.8061 (recon: 0.6517, consist: 0.1201, space: 1.6700, time: 1.7538)
  Val Loss:   12.8380 (recon: 12.8330, consist: 0.0025, space: 0.0182, time: 0.2270)
  [OK] æ–°çš„æœ€ä½³éªŒè¯æŸå¤±! æ¨¡åž‹å·²ä¿å­˜.

Epoch 13/20
  Train Loss: 0.1107 (recon: 0.1059, consist: 0.0031, space: 0.0806, time: 0.0913)
  Val Loss:   7.5842 (recon: 7.5834, consist: 0.0002, space: 0.0021, time: 0.0582)
  [OK] æ–°çš„æœ€ä½³éªŒè¯æŸå¤±! æ¨¡åž‹å·²ä¿å­˜.
```

**å…³é”®è§‚å¯Ÿç‚¹**:
1. **è®­ç»ƒæŸå¤±ä¸‹é™**: åº”è¯¥å¹³ç¨³ä¸‹é™
2. **éªŒè¯æŸå¤±é«˜äºŽè®­ç»ƒæŸå¤±**: æ­£å¸¸çŽ°è±¡ï¼ˆæ•°æ®åˆ†å¸ƒå·®å¼‚ï¼‰
3. **æŸå¤±ç»„ä»¶æ•°é‡çº§**: spaceå’Œtimeåº”è¯¥åœ¨0.1-2ä¹‹é—´
4. **Early Stopping**: éªŒè¯æŸå¤±10è½®ä¸ä¸‹é™ä¼šåœæ­¢

---

## 7. è¯„ä¼°æ–¹æ³•

### 7.1 è¯„ä¼°å‘½ä»¤

```bash
"venv_tf210_gpu\Scripts\python.exe" evaluate.py \
    --checkpoint_dir ./checkpoints/fixed_model \
    --output_dir ./results/fixed_model
```

### 7.2 è¯„ä¼°æŒ‡æ ‡

```python
# 1. RÂ² (å†³å®šç³»æ•°) - ä¸»è¦æŒ‡æ ‡
RÂ² = 1 - Î£(y_true - y_pred)Â² / Î£(y_true - y_mean)Â²
# èŒƒå›´: (-âˆž, 1]
# RÂ² = 1: å®Œç¾Žé¢„æµ‹
# RÂ² = 0: ç­‰åŒäºŽç”¨å‡å€¼å¡«è¡¥
# RÂ² < 0: æ¯”å‡å€¼å¡«è¡¥è¿˜å·®

# 2. MAE (å¹³å‡ç»å¯¹è¯¯å·®)
MAE = mean(|y_true - y_pred|)

# 3. RMSE (å‡æ–¹æ ¹è¯¯å·®)
RMSE = sqrt(mean((y_true - y_pred)Â²))

# 4. MAPE (å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®)
MAPE = mean(|y_true - y_pred| / |y_true|) Ã— 100%
```

### 7.3 è¾“å‡ºæ–‡ä»¶

| æ–‡ä»¶ | å†…å®¹ |
|------|------|
| `metrics.json` | æ•´ä½“æŒ‡æ ‡ (RÂ², MAE, RMSE, MAPE) |
| `feature_performance.csv` | 44ä¸ªç‰¹å¾å„è‡ªçš„æ€§èƒ½ |
| `prediction_vs_truth_scatter.png` | é¢„æµ‹vsçœŸå®žå€¼æ•£ç‚¹å›¾ |
| `error_distribution.png` | è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾ |
| `timeseries_sample_*.png` | 5ä¸ªæ ·æœ¬çš„æ—¶é—´åºåˆ—å¯è§†åŒ– |

---

## 8. å…³é”®Bugä¿®å¤

### Bug 1: æ•°æ®æ³„éœ² (2024-11-18ä¿®å¤)

#### é—®é¢˜æè¿°
åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè®¡ç®—å½’ä¸€åŒ–å‚æ•°ï¼ˆå‡å€¼ã€æ ‡å‡†å·®ï¼‰ï¼Œå¯¼è‡´æµ‹è¯•é›†çš„ç»Ÿè®¡ä¿¡æ¯æ³„éœ²åˆ°è®­ç»ƒè¿‡ç¨‹ä¸­ã€‚

#### å‘çŽ°è¿‡ç¨‹
```python
# è¿è¡Œè¯Šæ–­è„šæœ¬
python diagnose.py

# è¾“å‡ºæ˜¾ç¤ºé—®é¢˜
[X] å½“å‰æ–¹å¼ï¼ˆæ•´ä¸ªæ•°æ®é›†å½’ä¸€åŒ–ï¼‰:
  éªŒè¯é›†å‡å€¼: -0.406375  # âŒ åº”è¯¥æŽ¥è¿‘0
  æµ‹è¯•é›†å‡å€¼: 0.335865   # âŒ åº”è¯¥æŽ¥è¿‘0

[OK] æ­£ç¡®æ–¹å¼ï¼ˆåªåœ¨è®­ç»ƒé›†ä¸Šfitï¼‰:
  éªŒè¯é›†å‡å€¼: -0.821307  # âœ… å¯ä»¥ä¸ä¸º0
  æµ‹è¯•é›†å‡å€¼: 0.524690   # âœ… å¯ä»¥ä¸ä¸º0
```

#### ä¿®å¤æ–¹æ¡ˆ
**æ–‡ä»¶**: `data/preprocessor.py:363-450`

```python
# ä¿®å¤å‰ (é”™è¯¯)
def prepare_data(self):
    data = self.load_data()
    normalized = self.normalize(data, fit=True)  # âŒ æ•´ä¸ªæ•°æ®é›†
    windows = self.create_windows(normalized)
    splits = self.split_data(windows)  # ç„¶åŽæ‰åˆ’åˆ†
    return splits

# ä¿®å¤åŽ (æ­£ç¡®)
def prepare_data(self):
    data = self.load_data()

    # å…ˆåˆ’åˆ†åŽŸå§‹æ•°æ®
    train_data = data[:train_end]
    val_data = data[train_end:val_end]
    test_data = data[val_end:]

    # åªåœ¨è®­ç»ƒé›†ä¸Šfit
    train_norm = self.normalize(train_data, fit=True)   # âœ… fit
    val_norm = self.normalize(val_data, fit=False)      # âœ… transform
    test_norm = self.normalize(test_data, fit=False)    # âœ… transform

    # åˆ†åˆ«åˆ›å»ºçª—å£å’ŒæŽ©ç 
    train_windows = self.create_windows(train_norm)
    val_windows = self.create_windows(val_norm)
    test_windows = self.create_windows(test_norm)

    return {'train': train_windows, 'val': val_windows, 'test': test_windows}
```

#### å½±å“
- **ä¿®å¤å‰**: RÂ² = 0.255 (è™šå‡æ€§èƒ½ï¼ŒåŒ…å«æ•°æ®æ³„éœ²)
- **ä¿®å¤åŽ**: RÂ² = 0.691 (çœŸå®žæ€§èƒ½ï¼Œæ— æ•°æ®æ³„éœ²)

---

### Bug 2: æŸå¤±å‡½æ•°æ•°é‡çº§å¤±è¡¡ (2024-11-18ä¿®å¤)

#### é—®é¢˜æè¿°
ç©ºé—´å’Œæ—¶é—´æŸå¤±ä½¿ç”¨ `reduce_sum` å¯¼è‡´æ•°é‡çº§è¿‡å¤§ï¼ˆ~200ï¼‰ï¼Œè¿œè¶…é‡å»ºæŸå¤±ï¼Œç ´åè®­ç»ƒç¨³å®šæ€§ã€‚

#### å‘çŽ°è¿‡ç¨‹
```python
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
Train Loss: 5.4537 (recon: 0.6426, space: 213.3295, time: 258.7286)

# è®¡ç®—åŠ æƒè´¡çŒ®
Î»1 * L_recon = 1.0 * 0.64 = 0.64
Î»2 * L_space = 0.01 * 213 = 2.13  âŒ å ä¸»å¯¼ï¼
Î»3 * L_time = 0.01 * 258 = 2.58   âŒ å ä¸»å¯¼ï¼
```

#### ä¿®å¤æ–¹æ¡ˆ
**æ–‡ä»¶**: `models/losses.py:79-151`

```python
# ä¿®å¤å‰ (é”™è¯¯)
def spatial_preservation_loss(z_i, z_neighbors_spatial, mask):
    # ... è®¡ç®—weighted_distances: [batch, time, k]

    # å¯¹timeå’Œkç»´åº¦æ±‚å’Œï¼Œå¯¼è‡´æ•°é‡çº§è¿‡å¤§
    loss = tf.reduce_mean(tf.reduce_sum(weighted_distances, axis=[1, 2]))  # âŒ
    return loss

# ä¿®å¤åŽ (æ­£ç¡®)
def spatial_preservation_loss(z_i, z_neighbors_spatial, mask):
    # ... è®¡ç®—weighted_distances: [batch, time, k]

    # å¯¹æ‰€æœ‰ç»´åº¦æ±‚å¹³å‡ï¼Œä¿æŒæ•°é‡çº§ä¸€è‡´
    loss = tf.reduce_mean(weighted_distances)  # âœ…
    return loss
```

#### å½±å“
```
ä¿®å¤å‰:
  L_space = 213.33 â†’ åŠ æƒè´¡çŒ® = 2.13 (å ä¸»å¯¼)
  L_time = 258.73 â†’ åŠ æƒè´¡çŒ® = 2.58 (å ä¸»å¯¼)
  æ¨¡åž‹ä¼˜åŒ–æ–¹å‘è¢«ç©ºé—´/æ—¶é—´æŸå¤±ä¸»å¯¼ï¼Œé‡å»ºè´¨é‡ä¸‹é™

ä¿®å¤åŽ:
  L_space = 1.67 â†’ åŠ æƒè´¡çŒ® = 0.017 (åˆç†)
  L_time = 1.75 â†’ åŠ æƒè´¡çŒ® = 0.018 (åˆç†)
  æ¨¡åž‹ä¼˜åŒ–å¹³è¡¡ï¼Œé‡å»ºè´¨é‡æå‡
```

---

## 9. æ€§èƒ½ä¼˜åŒ–åŽ†ç¨‹

### 9.1 åŽ†å²ç‰ˆæœ¬æ€§èƒ½å¯¹æ¯”

| ç‰ˆæœ¬ | RÂ² | MAE | RMSE | å…³é”®å˜åŒ– |
|------|-----|-----|------|----------|
| evaluation | 0.040 | 0.436 | 0.598 | åˆå§‹æ¨¡åž‹ï¼Œè¿‡åº¦æ­£åˆ™åŒ– |
| reduced_reg | 0.255 | 0.389 | 0.527 | é™ä½Žæ­£åˆ™åŒ–ï¼ˆä½†æœ‰æ•°æ®æ³„éœ²ï¼‰ âŒ |
| config_A | -0.423 | 0.521 | 0.728 | Î»2/Î»3=0.05ï¼ˆè¿‡å¼ºï¼‰ âŒ |
| config_C | -0.075 | 0.450 | 0.633 | latent_dim=48ï¼ˆå®¹é‡è¿‡å¤§ï¼‰ âŒ |
| batch32 | -0.052 | 0.454 | 0.626 | batch_size=32ï¼ˆè¿‡æ‹Ÿåˆï¼‰ âŒ |
| **fixed_model** | **0.691** | **0.445** | **0.585** | **ä¿®å¤æ•°æ®æ³„éœ²+æŸå¤±å½’ä¸€åŒ–** âœ… |

### 9.2 æˆåŠŸçš„ä¼˜åŒ–

1. **é™ä½Žæ­£åˆ™åŒ–å¼ºåº¦**
   - dropout: 0.2 â†’ 0.1
   - l2_reg: 0.001 â†’ 0.0005
   - ç»“æžœ: RÂ² 0.04 â†’ 0.255

2. **ä¿®å¤æ•°æ®æ³„éœ²**
   - å…ˆåˆ’åˆ†å†å½’ä¸€åŒ–
   - ç»“æžœ: çœŸå®žRÂ²æ­ç¤ºä¸º0.691

3. **ä¿®å¤æŸå¤±æ•°é‡çº§**
   - reduce_sum â†’ reduce_mean
   - ç»“æžœ: è®­ç»ƒç¨³å®šæ€§æå‡

### 9.3 å¤±è´¥çš„ä¼˜åŒ–

1. **å¢žå¤§ç©ºé—´/æ—¶é—´æƒé‡**
   - Î»2/Î»3: 0.01 â†’ 0.05
   - ç»“æžœ: RÂ² -0.423 âŒ
   - åŽŸå› : çº¦æŸè¿‡å¼ºï¼Œé™åˆ¶æ¨¡åž‹å­¦ä¹ 

2. **å¢žå¤§æ¨¡åž‹å®¹é‡**
   - latent_dim: 32 â†’ 64
   - ç»“æžœ: è®­ç»ƒå¤±è´¥ âŒ
   - åŽŸå› : å®¹é‡è¿‡å¤§å¯¼è‡´è¿‡æ‹Ÿåˆ

3. **å¢žå¤§æ‰¹æ¬¡å¤§å°**
   - batch_size: 16 â†’ 32
   - ç»“æžœ: RÂ² -0.052 âŒ
   - åŽŸå› : æ‰¹æ¬¡å¤§å¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸‹é™

---

## 10. å¿«é€Ÿå¼€å§‹

### 10.1 ä¸€é”®è¿è¡Œ

```bash
# 1. æ¿€æ´»çŽ¯å¢ƒ
venv_tf210_gpu\Scripts\activate

# 2. è¿è¡Œè¯Šæ–­ï¼ˆå¯é€‰ï¼ŒéªŒè¯çŽ¯å¢ƒï¼‰
"venv_tf210_gpu\Scripts\python.exe" diagnose.py

# 3. è®­ç»ƒæ¨¡åž‹
"venv_tf210_gpu\Scripts\python.exe" train.py \
    --epochs 20 \
    --batch_size 16 \
    --latent_dim 32 \
    --lambda2 0.01 \
    --lambda3 0.01 \
    --dropout_rate 0.1 \
    --l2_reg 0.0005 \
    --checkpoint_dir ./checkpoints/my_model

# 4. è¯„ä¼°æ¨¡åž‹
"venv_tf210_gpu\Scripts\python.exe" evaluate.py \
    --checkpoint_dir ./checkpoints/my_model \
    --output_dir ./results/my_model

# 5. æŸ¥çœ‹ç»“æžœ
type results\my_model\metrics.json
```

### 10.2 ä½¿ç”¨çŽ°æœ‰æœ€ä½³æ¨¡åž‹

```bash
# ç›´æŽ¥è¯„ä¼°å·²è®­ç»ƒå¥½çš„æ¨¡åž‹
"venv_tf210_gpu\Scripts\python.exe" evaluate.py \
    --checkpoint_dir ./checkpoints/fixed_model \
    --output_dir ./results/my_evaluation
```

---

## 11. å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæ—¶å‡ºçŽ°NaN

**ç—‡çŠ¶**:
```
Epoch 5/20
  Train Loss: nan (recon: nan, consist: nan, ...)
```

**åŽŸå› **:
1. å­¦ä¹ çŽ‡è¿‡é«˜
2. æ¢¯åº¦çˆ†ç‚¸
3. æ•°æ®ä¸­æœ‰å¼‚å¸¸å€¼

**è§£å†³æ–¹æ¡ˆ**:
```bash
# é™ä½Žå­¦ä¹ çŽ‡
--learning_rate 0.0005

# å¢žåŠ æ­£åˆ™åŒ–
--l2_reg 0.001 --dropout_rate 0.2

# æ£€æŸ¥æ•°æ®
python diagnose.py
```

---

### Q2: éªŒè¯æŸå¤±è¿œé«˜äºŽè®­ç»ƒæŸå¤±

**ç—‡çŠ¶**:
```
Train Loss: 0.1
Val Loss:   7.5
```

**åŽŸå› **:
è¿™æ˜¯**æ­£å¸¸çŽ°è±¡**ï¼éªŒè¯é›†ä½¿ç”¨è®­ç»ƒé›†çš„å½’ä¸€åŒ–ç»Ÿè®¡é‡ï¼Œæ•°æ®åˆ†å¸ƒä¼šæœ‰å·®å¼‚ã€‚

**éªŒè¯æ˜¯å¦æ­£å¸¸**:
```bash
python diagnose.py
# æŸ¥çœ‹å½’ä¸€åŒ–æ£€æŸ¥éƒ¨åˆ†
```

---

### Q3: GPUå†…å­˜ä¸è¶³ (OOM)

**ç—‡çŠ¶**:
```
ResourceExhaustedError: OOM when allocating tensor
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å‡å°batch_size
--batch_size 8

# æˆ–å‡å°latent_dim
--latent_dim 16
```

---

### Q4: æŸäº›ç‰¹å¾RÂ²ä¸ºè´Ÿ

**ç—‡çŠ¶**:
```
feature_performance.csvä¸­æŸäº›ç‰¹å¾RÂ² < 0
```

**åŽŸå› **:
- è¿™äº›ç‰¹å¾æœ¬èº«æ–¹å·®å¤§æˆ–éš¾ä»¥é¢„æµ‹
- æ¨¡åž‹é¢„æµ‹æ•ˆæžœä¸å¦‚ç®€å•ç”¨å‡å€¼å¡«è¡¥

**è§£å†³æ–¹æ¡ˆ**:
- æ­£å¸¸çŽ°è±¡ï¼Œä¸éœ€è¦å¤„ç†
- æˆ–é’ˆå¯¹è¿™äº›ç‰¹å¾è¿›è¡Œç‰¹æ®Šçš„ç‰¹å¾å·¥ç¨‹

---

### Q5: è®­ç»ƒé€Ÿåº¦æ…¢

**å¯èƒ½åŽŸå› **:
1. æœªä½¿ç”¨GPU
2. FAISSæœªå®‰è£…
3. batch_sizeå¤ªå°

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. éªŒè¯GPU
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

# 2. å®‰è£…FAISS
pip install faiss-gpu

# 3. å¢žå¤§batch_size
--batch_size 32
```

---

## 12. ä¸‹ä¸€æ­¥å»ºè®®

### 12.1 çŸ­æœŸæ”¹è¿›
1. **å»¶é•¿è®­ç»ƒ**: epochs 20 â†’ 30-50
2. **ç‰¹å¾å·¥ç¨‹**: é’ˆå¯¹è¡¨çŽ°å·®çš„ç‰¹å¾è¿›è¡Œé¢„å¤„ç†
3. **é›†æˆå­¦ä¹ **: è®­ç»ƒå¤šä¸ªæ¨¡åž‹å–å¹³å‡

### 12.2 é•¿æœŸæ”¹è¿›
1. **æž¶æž„æ”¹è¿›**: å°è¯•Transformeræ›¿ä»£GRU
2. **æŸå¤±ä¼˜åŒ–**: è®¾è®¡è‡ªé€‚åº”æƒé‡Î»
3. **æ•°æ®å¢žå¼º**: æ·»åŠ æ›´å¤šæ•°æ®å¢žå¼ºç­–ç•¥

---

## 13. å‚è€ƒèµ„æ–™

### 13.1 å…³é”®æ–‡ä»¶
- **è®­ç»ƒè„šæœ¬**: `train.py`
- **è¯„ä¼°è„šæœ¬**: `evaluate.py`
- **è¯Šæ–­è„šæœ¬**: `diagnose.py`
- **æ•°æ®é¢„å¤„ç†**: `data/preprocessor.py:363-450`
- **æŸå¤±å‡½æ•°**: `models/losses.py:79-151`

### 13.2 é‡è¦é…ç½®
- **æœ€ä½³æ¨¡åž‹**: `checkpoints/fixed_model/`
- **æœ€ä½³é…ç½®**: `checkpoints/fixed_model/config.json`

### 13.3 æ€§èƒ½åŸºå‡†
- **RÂ² = 0.691** (ç¼ºå¤±ä½ç½®)
- **MAE = 0.445**
- **RMSE = 0.585**

---

## é™„å½•A: å®Œæ•´å‚æ•°åˆ—è¡¨

```bash
"venv_tf210_gpu\Scripts\python.exe" train.py \
    --data_path "D:\æ•°æ®è¡¥å…¨\hangmei_90_æ‹¼æŽ¥å¥½çš„.csv" \
    --epochs 20 \
    --batch_size 16 \
    --latent_dim 32 \
    --hidden_units 128 \
    --k_spatial 5 \
    --k_temporal 5 \
    --p_drop 0.1 \
    --n_corrupted 3 \
    --lambda1 1.0 \
    --lambda2 0.01 \
    --lambda3 0.01 \
    --learning_rate 0.001 \
    --missing_rate 0.2 \
    --missing_type MCAR \
    --use_faiss True \
    --dropout_rate 0.1 \
    --l2_reg 0.0005 \
    --seed 42 \
    --checkpoint_dir ./checkpoints/my_model
```

---

## é™„å½•B: è¯Šæ–­æ£€æŸ¥æ¸…å•

è¿è¡Œè¯Šæ–­è„šæœ¬éªŒè¯çŽ¯å¢ƒï¼š

```bash
python diagnose.py
```

**æ£€æŸ¥é¡¹ç›®**:
- [x] æ•°æ®é¢„å¤„ç†æ— æ³„éœ²
- [x] æŸå¤±ç»„ä»¶æ•°é‡çº§åˆç†
- [x] æ¨¡åž‹èƒ½è¿‡æ‹Ÿåˆå°æ•°æ®é›†

---

*æ–‡æ¡£ç‰ˆæœ¬: 1.1*
*æœ€åŽæ›´æ–°: 2025-11-19*
*æœ€ä½³æ¨¡åž‹æ€§èƒ½: RÂ² = 0.691, MAE = 0.445, RMSE = 0.585* âœ…
*è®­ç»ƒçŠ¶æ€: å·²å®Œæˆ (20 epochs, best_val_loss = 7.445)*
